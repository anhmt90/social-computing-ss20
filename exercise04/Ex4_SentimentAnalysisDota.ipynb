{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Computing/Social Gaming - Summer 2020\n",
    "\n",
    "# Exercise Sheet 4: Sentiment Analysis in DotA\n",
    "\n",
    "In this exercise we will work with data gathered from the popular MOBA *Defense of the Ancients 2* or short DotA 2, developed by Valve in 2013. If you are unfamiliar with this game, we provide a short introduction that should be enough to make you understand what the tasks demand from you:\n",
    "\n",
    "In Dota 2, two teams of 5 players play against each other on a single map, each team trying to destroy the enemy base, also called the ancient. In order to do this, they try to kill each other, earn gold and experience by killing non player characters called creeps to gain an advantage over the enemy. In every match, players first choose from a pool of 117 different heroes which are roughly divided into 2 groups: Carries, who start out weak and become much stronger once they accumulated a sufficient amount of gold to buy items they need, and supports, who start protect the carries in the early stages of a match, but tend to become less relevant in the later stages. Every team needs a balanced hero selection in order to have a chance of winning, as too many carries will have that team face a disadvantage early on, while too many supports may cause that team to struggle to win the game even once an advantage has been secured early.\n",
    "\n",
    "Psychologically speaking, DotA - or any MOBA for that matter - is an experiment on succesful team formation and cooperation, as 5 strangers meet each other for one match with the same goal, but usually different views on how to achieve it. Its real world equivalent would be any mash-up of people forced to work in a group, the only difference being that usually real-life situations don't involve another group working against them. \n",
    "\n",
    "Needless to say, the nature of the game does provoke negativity at times, and we want to try to predict it. More precisely, we want to find out whether we can infer negative player behavior from modelling the state of a game as a set of values.\n",
    "\n",
    "The .csv files provided for you contain information from 1.500 matches played during December 2016, and are split into 5 tables: \n",
    "\n",
    "- chat.csv : this table contains information about what was said in the chat between teams, when it was said and which player said it. We need the 'key', 'time' and 'slot' column as we are only interested in which team the players belong to, not their identities.\n",
    "- match.scsv: contains information about the game results. We only need the 'radiant_win' column from it, which tells us which team won.\n",
    "- players.csv : Detailed statistics for every player. 'kills' and 'deaths' columns are needed as we will need them to determine underperforming players\n",
    "- player_times.csv: Among other things the gold accumulated by every player, for every minute of a match, used to calculate the difference in gold earned between these teams.\n",
    "- labels.xlsx : a sample of labeled chat used for the sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.1: Your first sentiment analysis\n",
    "\n",
    "Sentiment analysis, sometimes called opinion mining, is a method to derive information from the text that allows for a classification as neutral, positive or negative. It is a semi-supervised process, meaning that you need a small set of labeled data to train your machine learning model on in order to use it on another set of unlabeled data. Without the labeled set it would be difficult for your AI to know what exactly makes a statement positive or negative. Some of its many practical applications are the analysis of customer reviews, social media comments or survey responses.\n",
    "\n",
    "**Note:** We will use a random forest classifier in this task.\n",
    "\n",
    "Your task is to train a model using the labeled data, then use that model to predict the sentiments of the whole chat. Let us start with the basics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Preparation\n",
    "\n",
    "Import the labels and split them into two arrays: the chat itself and the labels.\n",
    "\n",
    "A label is like a review of a single message:  \n",
    "-1 = negative  \n",
    " 0 = neutral   \n",
    " 1 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries needed for sentiment analysis\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#TODO: Import \"labels.xlsx\" and split it into 2 arrays: chat and labels.\n",
    "label_count = 450\n",
    "df = pd.read_excel('labels.xlsx', header=None)\n",
    "\n",
    "chat_data = df[0][:label_count]\n",
    "chat_labels = df[1][:label_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) How to train your model\n",
    "\n",
    "In this step you will use the chat and labels to train your random forest classifier. In order to do so, create the random forest classifier, fit it and make a prediction on the test set.\n",
    "\n",
    "After you are done, print the accuracy score and comment on it.\n",
    "\n",
    "**Hints:**\n",
    "- When creating the classifier, use n_estimators=200, random_state=0 as arguments.\n",
    "- The test should be 20% of the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ma-\n",
      "[nltk_data]     Anh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some words which do not have any valuable classification information. \n",
    "# We will use 'stopwords' to get rid of them.\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix:\n",
      " [[ 8 21  1]\n",
      " [ 5 51  0]\n",
      " [ 0  4  0]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.27      0.37        30\n",
      "     neutral       0.67      0.91      0.77        56\n",
      "    positive       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.43      0.39      0.38        90\n",
      "weighted avg       0.62      0.66      0.60        90\n",
      "\n",
      "\n",
      "Accuracy score:  0.6555555555555556\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "chat_data = [str(item) for item in chat_data]\n",
    "vectorizer = TfidfVectorizer(max_features=2500, min_df=3, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "chat_data = vectorizer.fit_transform(chat_data).toarray()\n",
    "\n",
    "# TODO: Create the random forest classifier, fit it and make a prediction on the test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(chat_data, chat_labels, test_size=0.2, random_state=0)\n",
    "# y_train --> ('neutral', 244) ('negative', 90) ('positive', 26)\n",
    "# y_test --> ('neutral', 56) ('negative', 30) ('positive', 4)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix(y_test, predictions))\n",
    "print('\\nClassification report:\\n', classification_report(y_test, predictions))\n",
    "print('\\nAccuracy score: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution for training data:  {'negative': 90, 'neutral': 244, 'positive': 26}\n"
     ]
    }
   ],
   "source": [
    "y_train_classes, y_train_counts = np.unique(y_train, return_counts=True)\n",
    "print('\\nClass distribution for training data: ', dict(zip(y_train_classes, y_train_counts.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Write your observations here:**\n",
    "\n",
    "From the class ditribution (`'negative': 90, 'neutral': 244, 'positive': 26`) of the training set and from the supports of the confusion matrix (whose $i$-th row and $j$-th column entry indicates the number of samples with true label being $i$-th class and prediced label being $j$-th class), we can see that we are dealing with an imbalanced dataset. Therefore, Accuracy Score is not a reliable performance measure in this case and we should rely on the f1-score measure shown in the classification report table.\n",
    "\n",
    "Since our goal is to predict negativity in game chats, samples with negative label are of greatest interest. In addition, accurately predicting negative chats is absolutely important for the label assignment and analysis performed in the later subtasks of this exercises, where negativity will be used as one of the predictors for predicting whether a team will lose a game or not.\n",
    "\n",
    "As false negatives (FN - wrongly predicting a chat not negative while it actually is) and false positives (FP - wrongly predicting a chat negative while it's not) impact equally on the correctness of the label assigning in substask 4.1.c and therefore the later analysis, the cost for FN and FP predictions would be more or less equal. This is another reason for F1-score, which is a measure of weighted average between precision and recall, to be used for evaluating the performance of the model. Unfortunately, our model with F1-score of $0.37$ for negative class will be unlikely assigning correct labels to negative chats in the next substask 4.1.c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Prediction time:\n",
    "\n",
    "Now you can use the model to predict the sentiments for the whole chat. Import the chat and predict the labels. You will need to use `vectorizer.transform().toarray()` on your data, but **DO NOT** use `fit()` anywhere! The classifier is already fitted, fitting it again effectively erases all it has learned.\n",
    "\n",
    "**Hint:** chat.csv includes ALL chatlines, including those that have been used in the previous steps and are already labeled. Don't label them again.\n",
    "\n",
    "**Note:** The chat table is massive. Labelling all of it may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction counts for unlabeled data:  {'negative': 3187, 'neutral': 41675, 'positive': 1457}\n",
      "['neutral' 'neutral' 'neutral' ... 'neutral' 'neutral' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "chatData = pd.read_csv(\"chat.csv\")\n",
    "unlabeled = chatData.iloc[:,1].values\n",
    "# TODO:\n",
    "unlabeled = [str(item) for item in unlabeled[label_count:]]\n",
    "unlabeled_tfidf = vectorizer.transform(unlabeled).toarray()\n",
    "predictions = rf.predict(unlabeled_tfidf)\n",
    "labels, counts = np.unique(predictions, return_counts=True)\n",
    "\n",
    "print('\\nPrediction counts for unlabeled data: ', dict(zip(labels.tolist(), counts.tolist())))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.2: Linear regression\n",
    "\n",
    "Linear regression is a technique that tries to find a correlation between a set of input variables x and a dependant variable y. In mathematical terms:\n",
    "\n",
    "$$y = \\alpha + \\beta X + \\epsilon$$\n",
    "\n",
    "where:\n",
    "- $X$ is the predictive vector, containing the (predictive) variables\n",
    "- $\\alpha$ and $\\beta$ are the model's parameters, where $\\alpha$ is the intercept/bias, $\\beta$ the coefficient vector containing coefficients for each predictive variable\n",
    "- and $\\epsilon$ the prediction error.\n",
    "\n",
    "Note that the assumption made is that the relationship is linear. This is a special case of polynomial regression, where we would allow for e.g. squared relationships.\n",
    "\n",
    "Our dependant variable is the negativity in the chat. Therefore we need to convert our labels into numbers first: We will use 0 for neutral, -1 for negative and +1 for positive sentiments. This is, of course, a simplification, as not all negative statements are equally negative. But we need to acknowledge that it is simply impossible to make an accurate distinction without knowing any context. And if we knew that, there would be no point in doing this regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels into values\n",
    "sentiments = []\n",
    "for i in chat_labels:\n",
    "    if i == 'positive':\n",
    "        sentiments.append(1)\n",
    "    elif i == 'negative':\n",
    "        sentiments.append(-1)\n",
    "    else:\n",
    "        sentiments.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predictions:\n",
    "    if i == 'positive':\n",
    "        sentiments.append(1)\n",
    "    elif i == 'negative':\n",
    "        sentiments.append(-1)\n",
    "    elif i == 'neutral':\n",
    "        sentiments.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Preparation:\n",
    "\n",
    "1. First, we need to read the csv files and group them by `match_id`.\n",
    "\n",
    "2. We will create a dataframe containing all relevant information and each row will represent one match. An empty dataframe has already been created for you with all the columns you need to fill. Here is an explanation of what you need to put into each column:\n",
    "\n",
    "3. Create a list of tuples called `full_chatdata`, each tuple has the following structure: label, team.\n",
    "\n",
    "4. Create a list called `goldData` containing the gold advantage for every timestamp of a match (usually every minute).\n",
    "\n",
    "5. Create a list called `KDratios` of kill-death ratios for each player in a match, split into two parts, one for each team, called ratiosRadiant and ratiosDire.\n",
    "\n",
    "6. Add an additional column called `radiant_win` displaying the winning team using boolean.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- you can find the labels in the chatData dataframe\n",
    "- use the `slot` column to determine the team. 0 to 4 is for radiant, 5-9 is for dire\n",
    "- There is a column in the match.csv file called `radiant_win` that displays true if team radiant won, false if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chatData</th>\n",
       "      <th>goldData</th>\n",
       "      <th>KDratios</th>\n",
       "      <th>radiant_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, dire], [0, radiant], [0, radiant], [-1, d...</td>\n",
       "      <td>[0, -257, -255, -567, -550, -1037, -1131, -122...</td>\n",
       "      <td>[[3.0, 4.333333333333333, 0.0, 2.0, 6.66666666...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0, radiant], [0, radiant], [-1, radiant], [-...</td>\n",
       "      <td>[0, -480, -583, -964, -573, -821, -937, -1077,...</td>\n",
       "      <td>[[0.75, 0.9, 0.38461538461538464, 0.8, 0.54545...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1, dire], [-1, radiant], [1, dire], [-1, rad...</td>\n",
       "      <td>[0, 273, 700, 839, 177, 522, -373, -69, -383, ...</td>\n",
       "      <td>[[0.38461538461538464, 0.5454545454545454, 1.6...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, dire], [0, radiant], [0, dire], [0, dire]...</td>\n",
       "      <td>[0, -487, -157, -178, -69, -255, -497, -404, -...</td>\n",
       "      <td>[[0.3076923076923077, 1.8461538461538463, 1.54...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, dire], [0, radiant], [0, radiant], [0, di...</td>\n",
       "      <td>[0, 333, 240, 515, 1310, 1755, 2044, 2839, 303...</td>\n",
       "      <td>[[4.0, 4.5, 0.3333333333333333, 0.25, 3.0], [0...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            chatData  \\\n",
       "0  [[0, dire], [0, radiant], [0, radiant], [-1, d...   \n",
       "1  [[0, radiant], [0, radiant], [-1, radiant], [-...   \n",
       "2  [[1, dire], [-1, radiant], [1, dire], [-1, rad...   \n",
       "3  [[0, dire], [0, radiant], [0, dire], [0, dire]...   \n",
       "4  [[0, dire], [0, radiant], [0, radiant], [0, di...   \n",
       "\n",
       "                                            goldData  \\\n",
       "0  [0, -257, -255, -567, -550, -1037, -1131, -122...   \n",
       "1  [0, -480, -583, -964, -573, -821, -937, -1077,...   \n",
       "2  [0, 273, 700, 839, 177, 522, -373, -69, -383, ...   \n",
       "3  [0, -487, -157, -178, -69, -255, -497, -404, -...   \n",
       "4  [0, 333, 240, 515, 1310, 1755, 2044, 2839, 303...   \n",
       "\n",
       "                                            KDratios  radiant_win  \n",
       "0  [[3.0, 4.333333333333333, 0.0, 2.0, 6.66666666...         True  \n",
       "1  [[0.75, 0.9, 0.38461538461538464, 0.8, 0.54545...        False  \n",
       "2  [[0.38461538461538464, 0.5454545454545454, 1.6...        False  \n",
       "3  [[0.3076923076923077, 1.8461538461538463, 1.54...        False  \n",
       "4  [[4.0, 4.5, 0.3333333333333333, 0.25, 3.0], [0...         True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Read the csv files and group them by match id\n",
    "chatData = pd.read_csv(\"chat.csv\")\n",
    "chatData = chatData.drop(['unit'],axis=1)\n",
    "chatData['label'] = sentiments # We are assigning labels to the chat messages\n",
    "chatData = chatData.groupby('match_id')\n",
    "player_times = pd.read_csv(\"player_time.csv\")\n",
    "player_times = player_times.groupby('match_id')\n",
    "match_info = pd.read_csv(\"match.csv\")\n",
    "radiant_win = match_info['radiant_win']\n",
    "player_info = pd.read_csv(\"players.csv\")\n",
    "player_info = player_info[['match_id', 'kills','deaths']]\n",
    "player_info = player_info.groupby('match_id')\n",
    "\n",
    "\n",
    "# 2. Create the dataframe\n",
    "dataframe = pd.DataFrame(columns = ['chatData','goldData', 'KDratios', 'radiant_win'])\n",
    "\n",
    "# 3.\n",
    "full_chatdata = []\n",
    "\n",
    "for name, group in chatData:\n",
    "    chat_data_line = []\n",
    "    for index,row in group.iterrows():\n",
    "        chat_tuple = []\n",
    "        # TODO: Create a list of tuples called full_chatdata, each tuple has the following structure: label, team.\n",
    "        # Hint 1: use the label column to determine the negativity/positivity of the message\n",
    "        # Hint 2: use the 'slot' column to determine the team. 0 to 4 is for radiant, 5-9 is for dire.\n",
    "        team = 'radiant' if 0 <= row['slot'] <= 4 else 'dire'\n",
    "        chat_tuple = [row['label'], team]\n",
    "        chat_data_line.append(chat_tuple)\n",
    "    full_chatdata.append(chat_data_line)\n",
    "        \n",
    "# 4. Create a list containing the gold advantage\n",
    "full_golddata =[]\n",
    "\n",
    "for name,group in player_times:\n",
    "    radiantAdv =[]\n",
    "    for index, row in group.iterrows():\n",
    "        radiantAdv.append((row['gold_t_0']+row['gold_t_1']+row['gold_t_2']+row['gold_t_3']+row['gold_t_4'])-\n",
    "            (row['gold_t_128']+row['gold_t_129']+row['gold_t_130']+row['gold_t_131']+row['gold_t_132']))\n",
    "        \n",
    "    full_golddata.append(radiantAdv)\n",
    "\n",
    "\n",
    "# 5.\n",
    "full_playerinfo = []\n",
    "for name, group in player_info:\n",
    "    playerinfo = []\n",
    "    for index, row in group.iterrows():\n",
    "        killsdeaths = []\n",
    "        killsdeaths.append(row['kills'])\n",
    "        killsdeaths.append(row['deaths'])\n",
    "        playerinfo.append(killsdeaths)\n",
    "    full_playerinfo.append(playerinfo)\n",
    "\n",
    "full_KDRatios = []\n",
    "\n",
    "for row in full_playerinfo:\n",
    "    KDRatios = []\n",
    "    ratiosRadiant =[]\n",
    "    ratiosDire = []\n",
    "    for i,player in enumerate(row):\n",
    "        # TODO: Create a list called [...] kill-death ratios for each player\n",
    "        # Hint: For each game the kd ratios should look like the following: \n",
    "        # [[RadiantPlayer0KD, ... RadiantPlayer4KD],[DirePlayer0KD, ... DirePlayer4KD]] \n",
    "        kills = player[0]\n",
    "        deaths = player[1]\n",
    "        ratio = (kills / deaths) if deaths != 0 else float(kills)\n",
    "        if i < 5:\n",
    "            ratiosRadiant.append(ratio)\n",
    "        else:\n",
    "            ratiosDire.append(ratio)\n",
    "\n",
    "    KDRatios.append(ratiosRadiant)\n",
    "    KDRatios.append(ratiosDire)\n",
    "    full_KDRatios.append(KDRatios)\n",
    "        \n",
    "# We add the newly created columns to our dataframe       \n",
    "dataframe['chatData'] = full_chatdata\n",
    "dataframe['goldData'] = full_golddata\n",
    "dataframe['radiant_win'] = radiant_win\n",
    "dataframe['KDratios'] = full_KDRatios\n",
    "        \n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Per-match analysis:\n",
    "\n",
    "As you may have noticed, the gold variables are gathered every minute, but the chat times are irregular. We could try to group the chat into 60 second timeframes that would correspond with the gold values, but this would be too tedious. Instead, we will simplify this by looking at the game as a whole:\n",
    "\n",
    "1. Compute the average negativity for each team by iterating over the list of tuples you created in exercise 4.2.3.\n",
    "\n",
    "2. Then, compute the average gold advantage for each match, and add a column for the gold advantage at the end of a match. The gold advantage at the end of a match is the last value of the list.\n",
    "\n",
    "3. Create a new column for the difference in negativity between the two teams.\n",
    "\n",
    "4. The kill/death ratios aren't very useful in the current format. Take the lowest K/D ratio from each team and create new columns for them. The reasoning behind this is that a low K/D ratio is a sign of underperformance of a player and players who do not perform on an acceptable level are usually harassed more often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chatData</th>\n",
       "      <th>goldData</th>\n",
       "      <th>KDratios</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>toxicityR</th>\n",
       "      <th>toxicityD</th>\n",
       "      <th>goldEnd</th>\n",
       "      <th>diff</th>\n",
       "      <th>worstKDR</th>\n",
       "      <th>worstKDD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, dire], [0, radiant], [0, radiant], [-1, d...</td>\n",
       "      <td>5405.651163</td>\n",
       "      <td>[[3.0, 4.333333333333333, 0.0, 2.0, 6.66666666...</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.173913</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>22365</td>\n",
       "      <td>0.040373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0, radiant], [0, radiant], [-1, radiant], [-...</td>\n",
       "      <td>-7245.478261</td>\n",
       "      <td>[[0.75, 0.9, 0.38461538461538464, 0.8, 0.54545...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-35698</td>\n",
       "      <td>-0.436364</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1, dire], [-1, radiant], [1, dire], [-1, rad...</td>\n",
       "      <td>-4928.145833</td>\n",
       "      <td>[[0.38461538461538464, 0.5454545454545454, 1.6...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>-26720</td>\n",
       "      <td>-0.184524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0, dire], [0, radiant], [0, dire], [0, dire]...</td>\n",
       "      <td>-2074.759259</td>\n",
       "      <td>[[0.3076923076923077, 1.8461538461538463, 1.54...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.214286</td>\n",
       "      <td>-7919</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0, dire], [0, radiant], [0, radiant], [0, di...</td>\n",
       "      <td>13510.088235</td>\n",
       "      <td>[[4.0, 4.5, 0.3333333333333333, 0.25, 3.0], [0...</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>41280</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            chatData      goldData  \\\n",
       "0  [[0, dire], [0, radiant], [0, radiant], [-1, d...   5405.651163   \n",
       "1  [[0, radiant], [0, radiant], [-1, radiant], [-...  -7245.478261   \n",
       "2  [[1, dire], [-1, radiant], [1, dire], [-1, rad...  -4928.145833   \n",
       "3  [[0, dire], [0, radiant], [0, dire], [0, dire]...  -2074.759259   \n",
       "4  [[0, dire], [0, radiant], [0, radiant], [0, di...  13510.088235   \n",
       "\n",
       "                                            KDratios  radiant_win  toxicityR  \\\n",
       "0  [[3.0, 4.333333333333333, 0.0, 2.0, 6.66666666...         True  -0.173913   \n",
       "1  [[0.75, 0.9, 0.38461538461538464, 0.8, 0.54545...        False  -0.636364   \n",
       "2  [[0.38461538461538464, 0.5454545454545454, 1.6...        False  -0.375000   \n",
       "3  [[0.3076923076923077, 1.8461538461538463, 1.54...        False   0.000000   \n",
       "4  [[4.0, 4.5, 0.3333333333333333, 0.25, 3.0], [0...         True  -0.333333   \n",
       "\n",
       "   toxicityD  goldEnd      diff  worstKDR  worstKDD  \n",
       "0  -0.214286    22365  0.040373  0.000000  0.071429  \n",
       "1  -0.200000   -35698 -0.436364  0.384615  0.166667  \n",
       "2  -0.190476   -26720 -0.184524  0.000000  0.833333  \n",
       "3  -0.214286    -7919  0.214286  0.117647  0.263158  \n",
       "4  -0.500000    41280  0.166667  0.250000  0.090909  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import  svm \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statistics import mean\n",
    "\n",
    "\n",
    "# 1. Average negativity\n",
    "radiantToxicity_full = []\n",
    "direToxicity_full = []\n",
    "\n",
    "for index, row in dataframe.iterrows():\n",
    "    radiantToxicity = 0\n",
    "    direToxicity = 0\n",
    "    # These counters keep of track of the number of messages each team wrote:\n",
    "    radiantcounter = 0\n",
    "    direcounter = 0\n",
    "    for tup in row['chatData']:\n",
    "        # TODO: Calculate each team's toxicity by summing all labels of a match.\n",
    "        # Hint: Don't forget to keep count of the number of messages written by each team.\n",
    "        label, team = tup\n",
    "        if team == 'radiant':\n",
    "            radiantcounter += 1\n",
    "            if label == -1:\n",
    "                radiantToxicity += label\n",
    "        elif team == 'dire':\n",
    "            direcounter += 1\n",
    "            if label == -1:\n",
    "                direToxicity += label\n",
    "\n",
    "    radiantToxicity_full.append(radiantToxicity / radiantcounter if radiantcounter != 0 else radiantToxicity)\n",
    "    direToxicity_full.append(direToxicity / direcounter if direcounter != 0 else radiantToxicity)\n",
    "        \n",
    "# 2. Average gold\n",
    "goldAverages = []\n",
    "goldEnd = []\n",
    "for index, row in dataframe.iterrows():\n",
    "    # TODO: Compute the average gold advantage for each match, as well as the gold advantage at the end of the match.\n",
    "    # Hint: The column goldData contains a list with gold advantage per minutes.\n",
    "    goldAverages.append(sum(row['goldData']) / len(row['goldData']))\n",
    "    goldEnd.append(row['goldData'][-1])\n",
    "    \n",
    "# 3. Difference in negativity\n",
    "differences = []\n",
    "# TODO: Compute the difference in negativity between the 2 teams.\n",
    "differences = np.array(radiantToxicity_full) - np.array(direToxicity_full)\n",
    "differences = differences.tolist()\n",
    "\n",
    "# 4. K/D ratios\n",
    "worstRadiant = []\n",
    "worstDire = []\n",
    "for index, row in dataframe.iterrows():\n",
    "    # TODO: Take the lowest K/D ratio from each team and create new columns for them.\n",
    "    worstRadiant.append(min(row['KDratios'][0]))\n",
    "    worstDire.append(min(row['KDratios'][1]))\n",
    "    \n",
    "# We add the newly created columns to our dataframe       \n",
    "dataframe['toxicityR'] = radiantToxicity_full\n",
    "dataframe['toxicityD'] = direToxicity_full\n",
    "dataframe['goldData'] = goldAverages\n",
    "dataframe['goldEnd'] = goldEnd \n",
    "dataframe['diff'] = differences\n",
    "dataframe['worstKDR'] = worstRadiant\n",
    "dataframe['worstKDD'] = worstDire\n",
    "\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) A warm-up regression\n",
    "\n",
    "Before we test our hypothesis of whether or not the state of the game influences player behavior, we will perform a linear regression with only one input variable: The gold advantage. \n",
    "\n",
    "You have probably wondered why we just assume that the gold values would represent the state of a game, whether a team is losing or winning. So far, this has only been a theory, and we should test it, as it would not make sense to use it as a representation for the state of the game in the actual regression model, if it wasn't representative at all.\n",
    "\n",
    "1. Once again, split your data into a train set and test set, create a linear regression model, fit the data and print your score. Try it two times: Your dependant variable should always be `radiant_win`, your X should be the average gold advantage and the gold advantage at the end. \n",
    "\n",
    "2. Discuss the score you obtained! What do the results mean for the explanatory power of the gold variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression with single preditor X = goldData\n",
      "0.6641129670999255\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3df3RU9Z3/8ec7CQkGIkoCivyKWOuKXbWYA3ZbW622ii7ratdTabd2V7tZAXf7daunurqu1uJptVprsSJbcauosQUp6IqoWKstCCaK/BDQACIxCBhFhCI/398/ZjLMhJlkkvlx58frcc49M5/P/dy572Q+k3fe987cMXdHRESKV0nQAYiISLCUCEREipwSgYhIkVMiEBEpckoEIiJFrizoAHqipqbGa2trgw5DRCSvNDU1feDuAzr252UiqK2tpbGxMegwRETyipltiNevQ0MiIkVOiUBEpMgpEYiIFDklAhGRIpeWRGBm081si5mtSLD+TDP72MyWhpebotadZ2ZrzKzZzK5LRzwiIpK8dFUE/wuc18WYl9391PDyIwAzKwXuBcYCI4HxZjYyTTGJiEgS0pII3P0l4MMebDoaaHb3de6+B2gALkxHTCIikpxsniP4gpm9YWbzzOykcN9gYGPUmJZw3yHMrN7MGs2scevWrZmOVUQkp7z11lv8+Mc/Zu/evWl/7GwlgteA4e5+CvBL4PfhfoszNu4XJLj7NHevc/e6AQMO+WCciEhBcncuueQSTjjhBP7rv/6L1tbWtO8jK58sdvftUfefNrNfmVkNoQpgaNTQIUD6f0oRkTzU1NREXV1dpP3www8zfPjwtO8nK4nAzI4GNru7m9loQpVIG7ANON7MjgXeAy4FvpWNmEREctWBAwc444wzWLhwIQBHHXUUGzZsoKKiIiP7S0siMLPHgDOBGjNrAf4b6AXg7lOBfwAmmNk+YBdwqYe+I3OfmV0FzAdKgenuvjIdMYmI5KMFCxZwzjnnRNrz5s3jvPO6elNmaiwfv7O4rq7OddE5ESkke/fu5fjjj2fDhtB14T7/+c/z6quvUlpamrZ9mFmTu9d17Ncni0VEAva73/2O8vLySBJYtGgRr732WlqTQGfy8jLUIiKFYOfOnRx55JGRt4RecMEFPPnkk5jFe0Nl5qgiEBEJwH333Uffvn0jSWDlypU89dRTWU8CoIpARCSr2traqKmpibT/5V/+hWnTpgUYkSoCEZGsueWWW2KSwIYNGwJPAqCKQEQk4zZu3MiwYcMi7ZtuuolbbrklwIhiKRGIiGTQxIkTue+++yLtrVu3xlQFuUCHhkREMmDVqlWYWSQJ/PKXv8Tdcy4JgCoCEZG0cncuuugi5syZA4CZsX37dvr27RtwZImpIhARSZMlS5ZQUlISSQINDQ0cOHAgp5MAqCIQEUnZ/v37GTNmDE1NTQAMHTqU5uZmysvLA44sOaoIRERSMH/+fMrKyiJJ4Nlnn+Xdd9/NmyQAqghERHpkz5491NbWsmnTJgDGjBnDwoULKSnJv/+v8y9iEZGANTQ0UFFREUkCixcv5pVXXsnLJACqCEREkrZjxw6qqqoi7YsuuohZs2YFcn2gdMrP9CUikmX33HNPTBJYtWoVTzzxRN4nAVBFICLSqa1btzJw4MBIe+LEidx7770BRpR+qghERBK48cYbY5LAxo0bCy4JQJoSgZlNN7MtZrYiwfpvm9my8LLQzE6JWveOmS03s6Vmpu+fFJHAbdiwATNj8uTJAPzoRz/C3RkyZEjAkWVGug4N/S8wBXgowfr1wFfc/SMzGwtMA8ZErT/L3T9IUywiIj32ve99jwceeCDSbmtro3///gFGlHlpqQjc/SXgw07WL3T3j8LNV4DCTKsikrdWrlyJmUWSwNSpU3H3gk8CEMzJ4iuAeVFtB541Mwfud/e439JgZvVAPRBzXW8RkVS4OxdccAHz5oX+LFVUVNDW1kafPn0Cjix7snqy2MzOIpQIfhjV/UV3HwWMBSaZ2Zfjbevu09y9zt3rBgwYkIVoRaTQtX8SuD0JzJw5k08//bSokgBksSIws5OBXwNj3b2tvd/dW8O3W8xsNjAaeClbcYlI8dm/fz+jRo1i2bJlAIwYMYLVq1fTq1evgCMLRlYqAjMbBjwBfMfd34rq72NmVe33ga8Dcd95JCKSDk8//TRlZWWRJLBgwQLWrl1btEkA0lQRmNljwJlAjZm1AP8N9AJw96nATUA18Kvwp/D2uXsdcBQwO9xXBjzq7s+kIyYRkWi7d+9myJAhfPBB6A2KX/rSl/jjH/+Yt9cHSqe0JAJ3H9/F+u8B34vTvw445dAtRETS5+GHH+ayyy6LtBsbGznttNMCjCi36BITIlKwtm/fTr9+/SLtb37zmzz22GMFcX2gdFJNJCIF6a677opJAm+99RYNDQ1KAnGoIhCRgrJ582aOPvroSPv73/8+d999d4AR5T5VBCJSMH74wx/GJIHW1lYlgSQoEYhI3lu/fj1mxu233w7AbbfdhrszaNCggCPLDzo0JCJ57bLLLuPhhx+OtD/66COOOOKIACPKP6oIRCQvLVu2DDOLJIFf//rXuLuSQA+oIhCRvOLufO1rX2PBggUAVFVVsXnzZg477LCAI8tfqghEJG+8/PLLlJSURJLA7Nmz2b59u5JAilQRiEjO27dvHyeffDKrVq0C4IQTTmDFihWUlelPWDqoIhCRnDZ37lx69eoVSQIvvvgiq1evVhJII/0mRSQn7dq1i0GDBvHxxx8DcNZZZ7FgwQJ9MjgDVBGISM558MEHqaysjCSBpUuX8sILLygJZIgqAhHJGdu2bePII4+MtL/97W8zY8aMACMqDqoIRCQn3H777TFJYO3atUoCWaKKQEQCtWnTJo455phI+5prruGOO+4IMKLio0QgIoH5wQ9+wF133RVpb9q0KeaicZIdOjQkIlnX3NyMmUWSwB133IG7KwkERBWBiGTV+PHjaWhoiLS3bdsW8wUykn1pqQjMbLqZbTGzFQnWm5ndY2bNZrbMzEZFrTvPzNaE112XjngkPR55BGproaQkdPvII5kf190xNTWhJXp8+3ozKC0N3UYvNTVwzjlQVhZql5WF2u3bJLOUlECvXsmNramBioquHy/Zfefv8jpmFpUE/hdwjjiiX9KP0bs3TJwY+p0m+t2VlkLfvonnUMc5NnHiwee+fU50No8nTjw4Lt6+kn09JJJo+1Qft1PunvICfBkYBaxIsP58YB5gwOnA4nB/KbAWGAGUA28AI7va32mnneaSWTNmuFdWusPBpbIy1J+pcT0dE72Ul7v36pV4vZYglv0OX3YgvPR32JW1/UfPoa7mT6Lt2k2Y0Pk28eZfvMfp7utuwoTkXmddARrd4/yNjtfZkwWo7SQR3A+Mj2qvAQYBXwDmR/VfD1zf1b6UCDJv+PD4E3348MyNS2WMllxd/uAHEwAOTwYSR/sc6u786TiPS0tT239PX3eJ9pvs47ZLlAiydY5gMLAxqt0S7ovXPybeA5hZPVAPMGzYsMxEKRHvvptcfzrHpTJGcs1eYCTQHG5/DnidoE5Lts+b7s6fjuP3709t/z0dl2i/6Xo9ZOtdQxanzzvpP7TTfZq717l73YABA9IanBwqUa7t2J/OcamMkVzyBKEjve1J4E/AcoJ8b0r7vOnu/Ok4vrQ0tf33dFyi/abr9ZCtRNACDI1qDwFaO+mXgE2eDJWVsX2VlaH+TI3r6Zho5eWhk7gShL8AlcA3wu1zgQPAFwOLCGLnUFfzJ9F27errO98m3vyL9ziJJHoN1Ncn9zrrsXjHi3qy0Pk5gguIPVm8JNxfBqwDjuXgyeKTutqXzhFkx4wZoWOQZqHbRCem0jmuu2Oqq0NL9Pj29eBeUnLocdXqavezzz543LW0NNTuzvFjM/eysuTGVleHTiJ29XhBHDtP33K/Q/S5gOUZ2U9FRejEaXV14t9dSYl7nz6J51DHOTZhwsHnvn1OdDaPJ0w4OC7evpJ9PSSSaPtUH9fdE54jsNC61JjZY8CZQA2wGfhvoFc40Uy10CUDpwDnEfq34Z/dvTG87fnA3YTeQTTd3bvMcXV1dd7Y2Jhy3CKSmo8++oj+/ftH2v/0T//Egw8+GGBE0hkza3L3uo79aTlo5+7ju1jvwKQE654Gnk5HHCKSPZMnT+bGG2+MtNevX09tbW1wAUmP6ZPFItIt7733HkOGDIm0r7/+em677bYAI5JUKRGISNL+7d/+jSlTpkTamzdvZuDAgQFGJOmgi86JSJfWrFmDmUWSwN133427KwkUCFUEIpKQu3PJJZcwa9asSN/27dupqqoKMCpJN1UEIhJXY2MjJSUlkSQwY8YM3F1JoACpIhCRGAcOHOBLX/oSixYtAuCoo45iw4YNVFRUBByZZIoqAhGJeP755yktLY0kgXnz5vH+++8rCRQ4VQQiwp49e/jMZz7Dxo2ha0COGjWKJUuWUNrTi+tIXlFFIFLkfvvb31JRURFJAosWLaKpqUlJoIioIhApUjt37qRfv37sD1/jeNy4ccyZM4fQFWGkmKgiEClC9913H3379o0kgZUrVzJ37lwlgSKlikCkiLS1tVFTUxNp19fXc//99wcYkeQCVQQiReLmm2+OSQIbNmxQEhBAFYFIwdu4cWPM17vedNNN3HLLLQFGJLlGiUCkgF155ZUx//Vv3bo1pioQAR0aEilIq1atwswiSWDKlCm4u5KAxKWKQKSAuDsXXnghTz75JAClpaVs27aNvn37BhyZ5DJVBCIFYvHixZSUlESSQENDA/v27VMSkC6pIhDJc/v372fMmDE0NTUBMHToUJqbmykvLw84MskXaakIzOw8M1tjZs1mdl2c9dea2dLwssLM9ptZ//C6d8xseXidvpFepBueeeYZysrKIkng2Wef5d1331USkG5JuSIws1LgXuBrQAvwqpnNdfc328e4+x3AHeHx44Cr3f3DqIc5y90/SDUWkWKxe/duamtref/99wEYM2YMCxcupKRER3ul+9Ixa0YDze6+zt33AA3AhZ2MHw88lob9ihSlRx99lN69e0eSwJIlS3jllVeUBKTH0nGOYDCwMardAoyJN9DMKoHzgKuiuh141swcuN/dpyXYth6oB2I+HCNSLD755BMOP/zwSPviiy9m5syZuj6QpCwd/0LEm4WeYOw44M8dDgt90d1HAWOBSWb25Xgbuvs0d69z97oBAwakFrFInrnnnntiksDq1auZNWuWkoCkRToqghZgaFR7CNCaYOyldDgs5O6t4dstZjab0KGml9IQl0je27p1KwMHDoy0J02axJQpUwKMSApROiqCV4HjzexYMysn9Md+bsdBZtYP+AowJ6qvj5lVtd8Hvg6sSENMInnvhhtuiEkCLS0tSgKSESlXBO6+z8yuAuYDpcB0d19pZleG108ND70IeNbdd0ZtfhQwO1zelgGPuvszqcYkks82bNhAbW1tpH3rrbdy4403BheQFDxzT3Q4P3fV1dV5Y6M+ciCF54orrmD69OmRdltbG/379w8wIikkZtbk7nUd+/V+M5EcsGLFCswskgSmTp2KuysJSFboEhMiAXJ3zj//fJ55JnREtHfv3rS1tVFZWRlwZFJMVBGIBKT9k8DtSWDmzJns2rVLSUCyThWBSJbt3bs35lpAI0aMYPXq1fTq1SvAqKSYqSIQyaKf//znMUnghRdeYO3atUoCEihVBCJZsHPnzkO+F2D//v26PpDkBM1CkQy75pprYpLA//3f/+HuSgKSM1QRiGRIx8tDlJWVsWfPHl0fSHKO/iURyYBLLrkkJgksXryYvXv3KglITlJFIJJG69at47jjjou0TzzxRN58881OthAJnioCkTQZNWpUTBJYs2aNkoDkBSUCkRQ1NTVhZrz++usA/O3f/i3uzmc/+9mAIxNJjg4NiaSgqqqKHTt2RNqbNm3i6KOPDjAike5TRSDSA88++yxmFkkCkyZNwt2VBCQvqSIQ6YYDBw5QWloa07d9+3aqqqoCikgkdaoIRJI0Y8aMmCTwk5/8BHdXEpC8p4pApAt79uyhoqIipm/37t0x1wwSyWeqCEQ6cccdd8QkgYceegh3VxKQgpKWisDMzgN+Qeg7i3/t7j/psP5MQl9avz7c9YS7/yiZbUWC8Mknn3D44YfH9OkicVKoUp7VZlYK3AuMBUYC481sZJyhL7v7qeHlR93cViRr/v3f/z0mCcyfP18XiZOClo6KYDTQ7O7rAMysAbgQSOYjlalsK5JW77//PoMGDYq0Kysr2blzZ4ARiWRHOv7FGQxsjGq3hPs6+oKZvWFm88zspG5uK5JR48aNi0kCjY2NSgJSNNJREcS7nKJ3aL8GDHf3HWZ2PvB74Pgktw3txKweqAcYNmxYz6MVifL222/HXAri1FNPjVwqQqRYpKMiaAGGRrWHAK3RA9x9u7vvCN9/GuhlZjXJbBv1GNPcvc7d6wYMGJCGsKXYnXTSSTFJYO3atUoCUpTSkQheBY43s2PNrBy4FJgbPcDMjrbwhdjNbHR4v23JbCuSbkuWLMHMIlcGvfjii3F3RowYEXBkIsFI+dCQu+8zs6uA+YTeAjrd3Vea2ZXh9VOBfwAmmNk+YBdwqbs7EHfbVGMSiaf9/f/79u2L9G3ZsgVVmFLsLPT3OL/U1dV5Y2Nj0GFIHnn66ae54IILIu3/+I//4M477wwwIpHsM7Mmd6/r2K9LTEhBi3eRuE8++STmy+RFip0+ISMF68EHH4xJAnfddRfuriQg0oEqAik4u3fvpnfv3jF9e/bsoVevXgFFJJLbVBFIQZk8eXJMEnjsscdwdyUBkU6oIpCC8PHHH3PEEUfE9B04cIDwu5ZFpBOqCCTv/eu//mtMEliwYAHuriQgkiRVBJK3WltbGTz44KWp+vfvT1tbW4ARieQnVQSSl84999yYJLB06VIlAZEeUkUgeWXVqlWMHHnwKytOP/10Fi1aFGBEIvlPiUDyxnHHHce6desi7fXr11NbWxtcQCIFQoeGJOctXLgQM4skgfHjx+PuSgIiaaKKQHJWvK+H/OCDD6iurg4oIpHCpIpActLcuXNjksB1112HuysJiGSAKgLJKfEuErdz504qKysDikik8KkikJzx/PPPxySBKVOm4O5KAiIZpopAArdnzx4+85nPsHHjRgBOPvlkmpqaKCvT9BTJBlUEEqjf/va3VFRURJLAokWLeOONN5QERLJIrzYJxI4dOzjiiCPYv38/AOPGjWPOnDm6PpBIAFQRSNb96le/oqqqKpIEVq5cydy5c5UERAKSlkRgZueZ2Rozazaz6+Ks/7aZLQsvC83slKh175jZcjNbamb6IuIC1tbWhpkxadIkAOrr63H3mEtGiEj2pZwIzKwUuBcYC4wExptZx1f2euAr7n4ycCswrcP6s9z91HhfqiyF4eabb6ampibSfvfdd7n//vsDjEhE2qWjIhgNNLv7OnffAzQAF0YPcPeF7v5RuPkKMCQN+5U8sHHjRsyMW265BYCbbroJd2fo0KEBRyYi7dJxsngwsDGq3QKM6WT8FcC8qLYDz5qZA/e7e8dqAQAzqwfqAYYNG5ZSwJIdV155Zcx//Vu3bo2pCkQkN6SjIoh3hs/jDjQ7i1Ai+GFU9xfdfRShQ0uTzOzL8bZ192nuXufudQMGDEg1ZsmgN998EzOLJIH2D4YpCYjkpnRUBC1AdJ0/BGjtOMjMTgZ+DYx198g3iLh7a/h2i5nNJnSo6aU0xCVZ5u783d/9HU899RQApaWlbNu2jb59+wYcmYh0Jh0VwavA8WZ2rJmVA5cCc6MHmNkw4AngO+7+VlR/HzOrar8PfB1YkYaYJMteeeUVSkpKIkmgoaGBffv2KQmI5IGUKwJ332dmVwHzgVJguruvNLMrw+unAjcB1cCvwu8V3xd+h9BRwOxwXxnwqLs/k2pMkj379+9n9OjRvPbaawAMHTqU5uZmysvLA45MRJJl7nEP5+e0uro6b2zURw6C9swzzzB27NhI+7nnnuOcc84JMCIR6YyZNcV7m74uMSHdtnv3boYPH87mzZuB0PcG//nPfz7kS2REJD/olSvd8uijj9K7d+9IEliyZAmLFi1SEhDJY6oIJCmffPIJhx9+eKR98cUXM3PmTF0fSKQA6N846dIvfvGLmCSwevVqZs2apSQgUiBUEUhCW7duZeDAgZH2pEmTmDJlSoARiUgmqCKQuG644YaYJNDS0qIkIFKglAgkxjvvvIOZcdtttwFw66234u4MHjw44MhEJFN0aEgiLr/8ch588MFIu62tjf79+wcYkYhkgyoCYfny5ZhZJAlMnToVd1cSECkSqgiKmLszduxY5s+fD0Dv3r1pa2ujsrIy4MhEJJtUERSp9k8CtyeBmTNnsmvXLiUBkSKkiqDI7N+/n89//vMsX74cgOOOO45Vq1bRq1evgCMTkaCoIigiTz31FGVlZZEk8MILL9Dc3KwkIFLkVBEUgU8//ZRjjjmGjz4KfW30GWecwYsvvqjrA4kIoIqg4D300EMcdthhkSTQ1NTESy+9pCQgIhGqCArUxx9/zBFHHBFpf/Ob3+Sxxx7T9YFE5BD6t7AA3XnnnTFJ4O2336ahoUFJQETiUkVQQDZv3szRRx8daV999dXcddddAUYkIvlAFUGBuPbaa2OSQGtrq5KAiCQlLYnAzM4zszVm1mxm18VZb2Z2T3j9MjMbley26fLII1BTA2ahpaYGJk6E2looKQndPvLIwbHR/RMnxm5rBocdFlpvBmVloTHRJk48uD7eUlIS2i7RuvbH6xj3ocs6zIyf/exn4T3/BHCOOWZQJ9uEfq6TTurscQt7qak5+Hx39nsuKYG+fUO3VVWHPucTJ8Z/Hvv2DT1ex7kVb35Fr+tqTHR/TU38fSTz+J29Tnq6reQxd09pAUqBtcAIoBx4AxjZYcz5wDzAgNOBxcluG2857bTTvDtmzHAvL3eHzpfKSvcJE0K3XY2Nt0yYENrfhAk9277jcvbZXcX9bQeilo/Sst9iWcrLQ3Njxgz3Xr0yu6/KyoP76ji/2tdFz9d4Y7qam4nGdHz8zl4nPd1W8gPQ6B7n73i8zu4swBeA+VHt64HrO4y5Hxgf1V4DDEpm23hLdxPB8OHJv2BLS3v+Yi8tDe0vlcdIblnqsQng11n/I1ooy/Dh3ZsfmdrX8OFdz9dk5lWiMdGP393XSTLbSn5IlAjScbJ4MLAxqt0CjElizOAktwXAzOqBeoBhw4Z1K8B3301+7P793XrouNum8hidc+Bs4A/hdhWwGTgsUzsseN2ZG5ncV/S6ROOSmVeJxiTzcyYak83fkQQjHecI4r0n0ZMck8y2oU73ae5e5+51AwYM6FaA3ckbpaXdeui426byGIm9ROjpak8Cvwe2oySQmmHDujc/MrWv6P5EY5KZV4nGJPMzJhObFKZ0JIIWYGhUewjQmuSYZLZN2eTJUF7e9bjKSqivD932RH197G2qzj4bevXaB/wV8JVw718Be4EL07OTIlZeHpobkydDpi+3VFl5cF8d51f7unaJxnQ1NxON6fj4iSQTmxSoeMeLurMQ+izCOuBYDp7wPanDmAuIPVm8JNlt4y3dPUfgHjrhVV198LhndXXoxNrw4e5modv2k2IzZsT2T5gQuy249+4dWt9+XLb9RHG7CRMOro+3mCU+nmsW2n727NkO0ecC/tjlMeLO9tnxuO/Ikdk5Np6LS3X1oSdoOz7H7b/PPn1Ct337HvqcT5gQ/3ns0yf0eB3nVrz5Fe9kbKIx0f3V1fH3kczjd/Y66em2kvtIcI7AQutSY2bnA3cTehfQdHefbGZXhhPNVAt9pHUKcB7wF+Cf3b0x0bZd7a+urs4bGxtTjjtX7dq1i4EDB7Jjxw4AvvrVr/L888/rk8EikhIza3L3ukP605EIsq2QE8H06dO54oorIu2lS5dyyimnBBiRiBSKRIlAl5jIEdu2bePII4+MtP/xH/+Rhx9+OMCIRKRY6BITOeCnP/1pTBJYu3atkoCIZI0qggC1trYyePDgSPvaa6/l9ttvDzAiESlGSgQBufrqq7n77rsj7ffff5+jjjoqwIhEpFjp0FCWvf3225hZJAn87Gc/w92VBEQkMKoIssTdGT9+PI8//nikb9u2bfTr1y/AqEREVBFkxWuvvUZJSUkkCfzmN7/B3ZUERCQnqCLIoAMHDnDmmWfy8ssvA1BdXU1LSwu9e/cOODIRkYNUEWTIH/7wB0pLSyNJ4KmnnuKDDz5QEhCRnKOKIM327t3LCSecwPr16wH467/+a15//XVKM3NJUhGRlKkiSKNZs2ZRXl4eSQJ/+tOfWLZsmZKAiOQ0VQRp8Je//IX+/fuze/duAM4991zmzZuni8SJSF5QRZCiadOm0adPn0gSWL58Oc8884ySgIjkDVUEPfThhx9SXV0daV9++eU88MADAUYkItIzqgh64NZbb41JAuvXr1cSEJG8pYqgG9577z2GDBkSaf/nf/4nk/U9fiKS55QIknTVVVdx7733RtpbtmxhwIABAUYkIpIeOjTUhTVr1mBmkSRw99134+5KAiJSMFQRJODufOMb32D27NmRvu3bt1NVVRVgVCIi6ZdSRWBm/c3sOTN7O3x7ZJwxQ83sD2a2ysxWmtn3o9bdbGbvmdnS8HJ+KvGky6uvvkpJSUkkCTzyyCO4u5KAiBSkVA8NXQcscPfjgQXhdkf7gB+4+4nA6cAkMxsZtf7n7n5qeHk6xXhScuDAAcaMGcPo0aMBGDRoEJ9++inf+ta3ggxLRCSjUk0EFwK/Cd//DfD3HQe4+yZ3fy18/xNgFTC447igPffcc5SWlrJkyRIA5s2bR2trKxUVFQFHJiKSWameIzjK3TdB6A++mQ3sbLCZ1QKfBxZHdV9lZpcBjYQqh48SbFsP1AMMGzYsxbAP2rNnD8cddxwtLS0AnHbaaSxevFjXBxKRotFlRWBmz5vZijjLhd3ZkZn1BWYB/8/dt4e77wOOA04FNgF3Jtre3ae5e52716XrHTuPP/44FRUVkSSwaNEiGhsblQREpKh0WRG4+zmJ1pnZZjMbFK4GBuAlSnoAAAWwSURBVAFbEozrRSgJPOLuT0Q99uaoMf8DPNWd4Htqx44d9OvXjwMHDgAwbtw45syZo+sDiUhRSvUcwVzgu+H73wXmdBxgob+uDwCr3P2uDusGRTUvAlakGE+X7r33XqqqqiJJ4M0332Tu3LlKAiJStFJNBD8BvmZmbwNfC7cxs2PMrP0dQF8EvgN8Nc7bRG83s+Vmtgw4C7g6xXg69cADD3DVVVcBUF9fj7tz4oknZnKXIiI5L6WTxe7eBpwdp78VOD98/09A3H+33f07qey/uz73uc/xN3/zNzQ0NDB06NBs7lpEJGcV1SeLx4wZw5///OegwxARySm61pCISJFTIhARKXJKBCIiRU6JQESkyCkRiIgUOSUCEZEip0QgIlLklAhERIqcuXvQMXSbmW0FNnRjkxrggwyFk2mKPRiKPRiKPbOGu/shl2/Oy0TQXWbW6O51QcfRE4o9GIo9GIo9GDo0JCJS5JQIRESKXLEkgmlBB5ACxR4MxR4MxR6AojhHICIiiRVLRSAiIgkoEYiIFLm8TARmdomZrTSzA2ZWF9Vfa2a7or4Sc2rUutPCX4vZbGb3hL9LGTOrMLPHw/2Lzaw2apvvmtnb4eW7pEGi2MPrrg/HscbMzs212DvEerOZvRfn60fT+nMEwczOC8febGbXBRlLOzN7J/y7W2pmjeG+/mb2XPg5fs7Mjowa363nIAPxTjezLWa2IqovbfFmcs4kiL1g5zsA7p53C3AicALwIlAX1V8LrEiwzRLgC4S+NnMeMDbcPxGYGr5/KfB4+H5/YF349sjw/SMzGPtI4A2gAjgWWAuU5lLsHX6Om4Fr4vSn7ecIaG6VhmMeAZSHf5aROTDn3wFqOvTdDlwXvn8d8NOePgcZiPfLwKjo12M6483knEkQe0HO9/YlLysCd1/l7muSHW9mg4DD3X2Rh377DwF/H159IfCb8P2ZwNnhzH0u8Jy7f+juHwHPAedlMPYLgQZ33+3u64FmYHQuxZ6kdP4cQRgNNLv7OnffAzSE48tF0b+33xD7++zuc5BW7v4S8GEG483YnEkQeyI5FXtP5WUi6MKxZva6mf3RzM4I9w0GWqLGtIT72tdtBHD3fcDHQHV0f5xtMiHR/nI59qvMbFm4lG4v89P5cwQh2897shx41syazKw+3HeUu28CCN8ODPf35DnIhnTGG8ScKcT5DuTwl9eb2fPA0XFW3eDucxJstgkY5u5tZnYa8HszO4lQadZR+/tmE63rbJtO9TD2nsSR9thjAurk5wDuA24NP+6twJ3A5T2MKS3xpkkuxRLti+7eamYDgefMbHUnYzM6LzIgH+ZMoc53IIcTgbuf04NtdgO7w/ebzGwt8FlC2XhI1NAhQGv4fgswFGgxszKgH6GysAU4s8M2L2Yq9qg4OsaY1dijJftzmNn/AE91iKljvD35OYKQKP5AuXtr+HaLmc0mdAhrs5kNcvdN4UMRW8LDe/IcZEM6483qnHH3ze33C2y+AwV2aMjMBphZafj+COB4YF24DP3EzE4PH4u7DGj/z3wu0P6umn8AXggf05sPfN3MjgyXgV8P92XKXODS8DsKjg3HviRXYw+/kNtdBLS/wyKdP0cQXgWON7Njzayc0Mm8uQHFAoCZ9TGzqvb7hJ7PFcT+3r5L7O+zu89BNqQz3qzOmQKe7yFBn63uyULoiWgh9N//ZmB+uP8bwEpCZ/FfA8ZFbVNH6MlbC0zh4KeqewO/I3SSZwkwImqby8P9zcA/ZzL28LobwvGtIerdHLkSe4ef42FgObCM0MQelImfI6D5dT7wVjjOG3Jgvo8Iz+k3wvP7hnB/NbAAeDt827+nz0EGYn6M0KHaveH5fkU6483knEkQe8HOd3fXJSZERIpdQR0aEhGR7lMiEBEpckoEIiJFTolARKTIKRGIiBQ5JQIRkSKnRCAiUuT+P91oqFvXdC8KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# TODO 1:\n",
    "print('Regression with single preditor X = goldData')\n",
    "X = dataframe['goldData'].to_numpy().reshape(-1, 1) # TODO \n",
    "y = dataframe['radiant_win'].to_numpy() # TODO\n",
    "\n",
    "# Splitting the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25) \n",
    "  \n",
    "regr = LinearRegression() \n",
    "  \n",
    "regr.fit(X_train, y_train) \n",
    "print(regr.score(X_test, y_test))\n",
    "\n",
    "y_pred = regr.predict(X_test) \n",
    "plt.scatter(X_test, y_test, color ='b') \n",
    "plt.plot(X_test, y_pred, color ='k') \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression with single preditor X = goldEnd\n",
      "0.8654432579876028\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Regression with single preditor X = goldEnd')\n",
    "X = dataframe['goldEnd'].to_numpy().reshape(-1, 1) # TODO \n",
    "y = dataframe['radiant_win'].to_numpy() # TODO\n",
    "\n",
    "# Splitting the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25) \n",
    "  \n",
    "regr = LinearRegression() \n",
    "  \n",
    "regr.fit(X_train, y_train) \n",
    "print(regr.score(X_test, y_test))\n",
    "\n",
    "y_pred = regr.predict(X_test) \n",
    "plt.scatter(X_test, y_test, color ='b') \n",
    "plt.plot(X_test, y_pred, color ='k') \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Write your observations here:**\n",
    "From the outputs above, we have the score for the model using single predictor `goldData` is $0.644$ and the score for the model using single predictor `goldEnd` is $0.85$. From the documentation of `sklearn.linear_model.LinearRegression`, the `score()` method returns the $R^2$ value of the model. This means, $R^2_{goldData} = 0.644$ and $R^2_{goldEnd} = 0.85$. This indicates that the independent variable `goldEnd` has more explanatory power for the state of a game than `goldData` does, and therefore, `goldEnd` is better a predictor for `radiant_win` than `goldData`. These values show that, $85\\%$ of the variation in `radiant_win` can be explained by the variation in the predictor `goldEnd`, while `goldData` accounts for $64.4\\%$ of the variation in `radiant_win`.\n",
    "\n",
    "However, look at the plots, we can by no means conclude that $R^2$ value indicates how well the regression line fit the data. Obviously, the relationship between the predictor `goldData` or `goldEnd` and the dependent variable `radiant_win` is not linear. To fit this data better, we need to choose a nonlinear method such as Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Testing our hypothesis\n",
    "\n",
    "**1.** Finally, we can do our linear regression. This time, use the gold data, the kill/death ratios and the negativity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00569518563591731\n"
     ]
    }
   ],
   "source": [
    "# TODO 1:\n",
    "# X = dataframe[dataframe.columns.difference(['chatData', 'radiant_win', 'KDratios'])].to_numpy() # TODO \n",
    "X = dataframe[['goldData', 'goldEnd', 'worstKDR', 'worstKDD']].to_numpy() # TODO \n",
    "Y = dataframe['diff'].to_numpy() # TODO\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "print(regr.score(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Discussion\n",
    "\n",
    "What is the score? What does that number mean? Discuss possible reasons for this result.  \n",
    "**Hint:** Take a peek at the labels.xlsx file and look at some of the most common negative words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Write your observations here:**\n",
    "The $R^2$ value of $0.0056951$ is low, which indicates that the set of predictors `goldData`, `goldEnd`, `worstKDR`, `worstKDD` accounts for almost none of the variation in the difference of negativity between two playing teams. In other words, there is no linear relationship between these four predictors and `diff`. However, there maybe exists a curvilinear/nonlinear relationship between them, for which we should allow higher orders of polynomial regression or the likes. The reasons might be:\n",
    "\n",
    "- Negative chats are often short, most of the time with only 1 to 4 words, so it is hard to infer whether those chats are about the state of a game or not. \n",
    "- Negative chats do not talk about the state of a game, but rather to solely insult or offend other people for their ego"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
